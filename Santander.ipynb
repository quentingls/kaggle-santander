{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading https://files.pythonhosted.org/packages/8d/04/65f961423898104bc3779b0be1e89973ee616840dedf49b385b18a1c34ff/kaggle-1.3.12.tar.gz\n",
      "Requirement already satisfied: urllib3<1.23.0,>=1.15 in /Users/quentin/anaconda3/lib/python3.6/site-packages (from kaggle)\n",
      "Requirement already satisfied: six>=1.10 in /Users/quentin/anaconda3/lib/python3.6/site-packages (from kaggle)\n",
      "Requirement already satisfied: certifi in /Users/quentin/anaconda3/lib/python3.6/site-packages (from kaggle)\n",
      "Requirement already satisfied: python-dateutil in /Users/quentin/anaconda3/lib/python3.6/site-packages (from kaggle)\n",
      "Requirement already satisfied: requests in /Users/quentin/anaconda3/lib/python3.6/site-packages (from kaggle)\n",
      "Requirement already satisfied: tqdm in /Users/quentin/anaconda3/lib/python3.6/site-packages (from kaggle)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/quentin/anaconda3/lib/python3.6/site-packages (from requests->kaggle)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /Users/quentin/anaconda3/lib/python3.6/site-packages (from requests->kaggle)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Running setup.py bdist_wheel for kaggle ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/quentin/Library/Caches/pip/wheels/61/d6/e6/38fc0e2316f49b91aafdaf9a8d7756a9906b2ad7e501c1e165\n",
      "Successfully built kaggle\n",
      "Installing collected packages: kaggle\n",
      "Successfully installed kaggle-1.3.12\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = read_csv('./data/train.csv')\n",
    "test_data = read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.set_index('ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing columns with only 0\n",
    "train_data = train_data.loc[:, (train_data != 0).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4459, 4736)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>48df886f9</th>\n",
       "      <th>0deb4b6a8</th>\n",
       "      <th>34b15f335</th>\n",
       "      <th>a8cb14b00</th>\n",
       "      <th>2f0771a37</th>\n",
       "      <th>30347e683</th>\n",
       "      <th>d08d1fbe3</th>\n",
       "      <th>6ee66e115</th>\n",
       "      <th>20aa07010</th>\n",
       "      <th>...</th>\n",
       "      <th>3ecc09859</th>\n",
       "      <th>9281abeea</th>\n",
       "      <th>8675bec0b</th>\n",
       "      <th>3a13ed79a</th>\n",
       "      <th>f677d4d13</th>\n",
       "      <th>71b203550</th>\n",
       "      <th>137efaa80</th>\n",
       "      <th>fb36b89d9</th>\n",
       "      <th>7e293fbaf</th>\n",
       "      <th>9fc776466</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000d6aaf2</th>\n",
       "      <td>38000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000fbd867</th>\n",
       "      <td>600000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2200000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0027d6b71</th>\n",
       "      <td>10000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0028cbf45</th>\n",
       "      <td>2000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002a68644</th>\n",
       "      <td>14400000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4736 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               target  48df886f9  0deb4b6a8  34b15f335  a8cb14b00  2f0771a37  \\\n",
       "ID                                                                             \n",
       "000d6aaf2  38000000.0        0.0          0        0.0          0          0   \n",
       "000fbd867    600000.0        0.0          0        0.0          0          0   \n",
       "0027d6b71  10000000.0        0.0          0        0.0          0          0   \n",
       "0028cbf45   2000000.0        0.0          0        0.0          0          0   \n",
       "002a68644  14400000.0        0.0          0        0.0          0          0   \n",
       "\n",
       "           30347e683  d08d1fbe3  6ee66e115  20aa07010    ...      3ecc09859  \\\n",
       "ID                                                       ...                  \n",
       "000d6aaf2          0          0          0        0.0    ...            0.0   \n",
       "000fbd867          0          0          0  2200000.0    ...            0.0   \n",
       "0027d6b71          0          0          0        0.0    ...            0.0   \n",
       "0028cbf45          0          0          0        0.0    ...            0.0   \n",
       "002a68644          0          0          0  2000000.0    ...            0.0   \n",
       "\n",
       "           9281abeea  8675bec0b  3a13ed79a  f677d4d13  71b203550  137efaa80  \\\n",
       "ID                                                                            \n",
       "000d6aaf2        0.0        0.0          0          0          0          0   \n",
       "000fbd867        0.0        0.0          0          0          0          0   \n",
       "0027d6b71        0.0        0.0          0          0          0          0   \n",
       "0028cbf45        0.0        0.0          0          0          0          0   \n",
       "002a68644        0.0        0.0          0          0          0          0   \n",
       "\n",
       "           fb36b89d9  7e293fbaf  9fc776466  \n",
       "ID                                          \n",
       "000d6aaf2          0          0          0  \n",
       "000fbd867          0          0          0  \n",
       "0027d6b71          0          0          0  \n",
       "0028cbf45          0          0          0  \n",
       "002a68644          0          0          0  \n",
       "\n",
       "[5 rows x 4736 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_data.drop([\"target\"], axis=1)\n",
    "train_y = np.log1p(train_data[\"target\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dev, x_val, y_dev, y_val = train_test_split(train_x, train_y, test_size=0.2) # consider random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lgbm(x_train, y_train, x_val, y_val, x_test):\n",
    "    params = {\n",
    "\"objective\": \"regression\",\n",
    "        \"metric\": \"rmse\",\n",
    "        \"num_leaves\": 40,\n",
    "        \"learning_rate\": 0.005,\n",
    "        \"bagging_fraction\": 0.7,\n",
    "        \"feature_fraction\": 0.5,\n",
    "        \"bagging_frequency\": 5,\n",
    "        \"bagging_seed\": 42,\n",
    "        \"verbosity\": -1,\n",
    "        \"seed\": 42,    \n",
    "    }\n",
    "    lgtrain = lgb.Dataset(x_train, label=y_train)\n",
    "    lgvalid = lgb.Dataset(x_val, label=y_val)\n",
    "    evals_result = {}\n",
    "    model = lgb.train(params, lgtrain, 3000,\n",
    "                      valid_sets=[lgtrain, lgvalid],\n",
    "                      evals_result = evals_result,\n",
    "                      early_stopping_rounds=100)\n",
    "    \n",
    "    y_hat_test = np.expm1(model.predict(x_test, num_iteration=model.best_iteration))\n",
    "    return y_hat_test, model, evals_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's rmse: 1.74304\tvalid_1's rmse: 1.76829\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[2]\ttraining's rmse: 1.74024\tvalid_1's rmse: 1.76623\n",
      "[3]\ttraining's rmse: 1.73748\tvalid_1's rmse: 1.76405\n",
      "[4]\ttraining's rmse: 1.73478\tvalid_1's rmse: 1.7619\n",
      "[5]\ttraining's rmse: 1.73208\tvalid_1's rmse: 1.75973\n",
      "[6]\ttraining's rmse: 1.72954\tvalid_1's rmse: 1.7578\n",
      "[7]\ttraining's rmse: 1.72702\tvalid_1's rmse: 1.75562\n",
      "[8]\ttraining's rmse: 1.72462\tvalid_1's rmse: 1.75361\n",
      "[9]\ttraining's rmse: 1.72213\tvalid_1's rmse: 1.75167\n",
      "[10]\ttraining's rmse: 1.71946\tvalid_1's rmse: 1.74957\n",
      "[11]\ttraining's rmse: 1.71675\tvalid_1's rmse: 1.74753\n",
      "[12]\ttraining's rmse: 1.71418\tvalid_1's rmse: 1.74562\n",
      "[13]\ttraining's rmse: 1.71165\tvalid_1's rmse: 1.74373\n",
      "[14]\ttraining's rmse: 1.70926\tvalid_1's rmse: 1.74187\n",
      "[15]\ttraining's rmse: 1.7067\tvalid_1's rmse: 1.73994\n",
      "[16]\ttraining's rmse: 1.70436\tvalid_1's rmse: 1.73817\n",
      "[17]\ttraining's rmse: 1.70178\tvalid_1's rmse: 1.73631\n",
      "[18]\ttraining's rmse: 1.69924\tvalid_1's rmse: 1.73438\n",
      "[19]\ttraining's rmse: 1.69674\tvalid_1's rmse: 1.73262\n",
      "[20]\ttraining's rmse: 1.69431\tvalid_1's rmse: 1.73077\n",
      "[21]\ttraining's rmse: 1.69171\tvalid_1's rmse: 1.72873\n",
      "[22]\ttraining's rmse: 1.6893\tvalid_1's rmse: 1.72685\n",
      "[23]\ttraining's rmse: 1.68687\tvalid_1's rmse: 1.72495\n",
      "[24]\ttraining's rmse: 1.68456\tvalid_1's rmse: 1.72331\n",
      "[25]\ttraining's rmse: 1.68222\tvalid_1's rmse: 1.72154\n",
      "[26]\ttraining's rmse: 1.67988\tvalid_1's rmse: 1.71976\n",
      "[27]\ttraining's rmse: 1.67751\tvalid_1's rmse: 1.71796\n",
      "[28]\ttraining's rmse: 1.67522\tvalid_1's rmse: 1.71602\n",
      "[29]\ttraining's rmse: 1.67286\tvalid_1's rmse: 1.71413\n",
      "[30]\ttraining's rmse: 1.67047\tvalid_1's rmse: 1.71225\n",
      "[31]\ttraining's rmse: 1.66806\tvalid_1's rmse: 1.71051\n",
      "[32]\ttraining's rmse: 1.66568\tvalid_1's rmse: 1.70878\n",
      "[33]\ttraining's rmse: 1.66331\tvalid_1's rmse: 1.70692\n",
      "[34]\ttraining's rmse: 1.66102\tvalid_1's rmse: 1.70539\n",
      "[35]\ttraining's rmse: 1.65865\tvalid_1's rmse: 1.70371\n",
      "[36]\ttraining's rmse: 1.65635\tvalid_1's rmse: 1.70197\n",
      "[37]\ttraining's rmse: 1.65418\tvalid_1's rmse: 1.70032\n",
      "[38]\ttraining's rmse: 1.65189\tvalid_1's rmse: 1.69853\n",
      "[39]\ttraining's rmse: 1.6496\tvalid_1's rmse: 1.6968\n",
      "[40]\ttraining's rmse: 1.64728\tvalid_1's rmse: 1.69503\n",
      "[41]\ttraining's rmse: 1.64505\tvalid_1's rmse: 1.69349\n",
      "[42]\ttraining's rmse: 1.6428\tvalid_1's rmse: 1.6919\n",
      "[43]\ttraining's rmse: 1.64054\tvalid_1's rmse: 1.69022\n",
      "[44]\ttraining's rmse: 1.63827\tvalid_1's rmse: 1.68857\n",
      "[45]\ttraining's rmse: 1.63616\tvalid_1's rmse: 1.68688\n",
      "[46]\ttraining's rmse: 1.63395\tvalid_1's rmse: 1.68517\n",
      "[47]\ttraining's rmse: 1.63181\tvalid_1's rmse: 1.6836\n",
      "[48]\ttraining's rmse: 1.62962\tvalid_1's rmse: 1.68216\n",
      "[49]\ttraining's rmse: 1.62753\tvalid_1's rmse: 1.68062\n",
      "[50]\ttraining's rmse: 1.62542\tvalid_1's rmse: 1.67909\n",
      "[51]\ttraining's rmse: 1.62331\tvalid_1's rmse: 1.67755\n",
      "[52]\ttraining's rmse: 1.62126\tvalid_1's rmse: 1.67596\n",
      "[53]\ttraining's rmse: 1.6191\tvalid_1's rmse: 1.67434\n",
      "[54]\ttraining's rmse: 1.61695\tvalid_1's rmse: 1.67289\n",
      "[55]\ttraining's rmse: 1.61494\tvalid_1's rmse: 1.6714\n",
      "[56]\ttraining's rmse: 1.6128\tvalid_1's rmse: 1.66983\n",
      "[57]\ttraining's rmse: 1.61067\tvalid_1's rmse: 1.66827\n",
      "[58]\ttraining's rmse: 1.60858\tvalid_1's rmse: 1.66687\n",
      "[59]\ttraining's rmse: 1.60655\tvalid_1's rmse: 1.66535\n",
      "[60]\ttraining's rmse: 1.60442\tvalid_1's rmse: 1.66386\n",
      "[61]\ttraining's rmse: 1.60244\tvalid_1's rmse: 1.66249\n",
      "[62]\ttraining's rmse: 1.60036\tvalid_1's rmse: 1.66102\n",
      "[63]\ttraining's rmse: 1.59836\tvalid_1's rmse: 1.6595\n",
      "[64]\ttraining's rmse: 1.59635\tvalid_1's rmse: 1.65823\n",
      "[65]\ttraining's rmse: 1.59431\tvalid_1's rmse: 1.65681\n",
      "[66]\ttraining's rmse: 1.59233\tvalid_1's rmse: 1.6555\n",
      "[67]\ttraining's rmse: 1.59042\tvalid_1's rmse: 1.65418\n",
      "[68]\ttraining's rmse: 1.5884\tvalid_1's rmse: 1.65281\n",
      "[69]\ttraining's rmse: 1.5864\tvalid_1's rmse: 1.65127\n",
      "[70]\ttraining's rmse: 1.58448\tvalid_1's rmse: 1.64996\n",
      "[71]\ttraining's rmse: 1.58244\tvalid_1's rmse: 1.64841\n",
      "[72]\ttraining's rmse: 1.58051\tvalid_1's rmse: 1.64712\n",
      "[73]\ttraining's rmse: 1.57858\tvalid_1's rmse: 1.6459\n",
      "[74]\ttraining's rmse: 1.57665\tvalid_1's rmse: 1.64451\n",
      "[75]\ttraining's rmse: 1.57474\tvalid_1's rmse: 1.64314\n",
      "[76]\ttraining's rmse: 1.57285\tvalid_1's rmse: 1.64172\n",
      "[77]\ttraining's rmse: 1.57092\tvalid_1's rmse: 1.64039\n",
      "[78]\ttraining's rmse: 1.56902\tvalid_1's rmse: 1.63913\n",
      "[79]\ttraining's rmse: 1.56709\tvalid_1's rmse: 1.63809\n",
      "[80]\ttraining's rmse: 1.56521\tvalid_1's rmse: 1.63681\n",
      "[81]\ttraining's rmse: 1.56336\tvalid_1's rmse: 1.63545\n",
      "[82]\ttraining's rmse: 1.56149\tvalid_1's rmse: 1.63427\n",
      "[83]\ttraining's rmse: 1.55967\tvalid_1's rmse: 1.6331\n",
      "[84]\ttraining's rmse: 1.55772\tvalid_1's rmse: 1.63195\n",
      "[85]\ttraining's rmse: 1.55582\tvalid_1's rmse: 1.63071\n",
      "[86]\ttraining's rmse: 1.55407\tvalid_1's rmse: 1.62972\n",
      "[87]\ttraining's rmse: 1.55226\tvalid_1's rmse: 1.62872\n",
      "[88]\ttraining's rmse: 1.55038\tvalid_1's rmse: 1.62749\n",
      "[89]\ttraining's rmse: 1.54863\tvalid_1's rmse: 1.62618\n",
      "[90]\ttraining's rmse: 1.54693\tvalid_1's rmse: 1.62482\n",
      "[91]\ttraining's rmse: 1.54514\tvalid_1's rmse: 1.62331\n",
      "[92]\ttraining's rmse: 1.54332\tvalid_1's rmse: 1.62215\n",
      "[93]\ttraining's rmse: 1.54157\tvalid_1's rmse: 1.62111\n",
      "[94]\ttraining's rmse: 1.53985\tvalid_1's rmse: 1.61995\n",
      "[95]\ttraining's rmse: 1.53808\tvalid_1's rmse: 1.61865\n",
      "[96]\ttraining's rmse: 1.53633\tvalid_1's rmse: 1.61759\n",
      "[97]\ttraining's rmse: 1.53463\tvalid_1's rmse: 1.61662\n",
      "[98]\ttraining's rmse: 1.5329\tvalid_1's rmse: 1.61549\n",
      "[99]\ttraining's rmse: 1.5312\tvalid_1's rmse: 1.61455\n",
      "[100]\ttraining's rmse: 1.52946\tvalid_1's rmse: 1.61346\n",
      "[101]\ttraining's rmse: 1.52767\tvalid_1's rmse: 1.61231\n",
      "[102]\ttraining's rmse: 1.52596\tvalid_1's rmse: 1.61119\n",
      "[103]\ttraining's rmse: 1.52425\tvalid_1's rmse: 1.61012\n",
      "[104]\ttraining's rmse: 1.52262\tvalid_1's rmse: 1.60895\n",
      "[105]\ttraining's rmse: 1.52092\tvalid_1's rmse: 1.60793\n",
      "[106]\ttraining's rmse: 1.51931\tvalid_1's rmse: 1.60695\n",
      "[107]\ttraining's rmse: 1.51764\tvalid_1's rmse: 1.60604\n",
      "[108]\ttraining's rmse: 1.51604\tvalid_1's rmse: 1.60511\n",
      "[109]\ttraining's rmse: 1.51439\tvalid_1's rmse: 1.60431\n",
      "[110]\ttraining's rmse: 1.51275\tvalid_1's rmse: 1.60331\n",
      "[111]\ttraining's rmse: 1.51111\tvalid_1's rmse: 1.60231\n",
      "[112]\ttraining's rmse: 1.50949\tvalid_1's rmse: 1.60134\n",
      "[113]\ttraining's rmse: 1.50778\tvalid_1's rmse: 1.6004\n",
      "[114]\ttraining's rmse: 1.50612\tvalid_1's rmse: 1.59935\n",
      "[115]\ttraining's rmse: 1.50451\tvalid_1's rmse: 1.59841\n",
      "[116]\ttraining's rmse: 1.50297\tvalid_1's rmse: 1.59721\n",
      "[117]\ttraining's rmse: 1.50139\tvalid_1's rmse: 1.59632\n",
      "[118]\ttraining's rmse: 1.49985\tvalid_1's rmse: 1.59536\n",
      "[119]\ttraining's rmse: 1.49821\tvalid_1's rmse: 1.59427\n",
      "[120]\ttraining's rmse: 1.49659\tvalid_1's rmse: 1.59318\n",
      "[121]\ttraining's rmse: 1.4949\tvalid_1's rmse: 1.59215\n",
      "[122]\ttraining's rmse: 1.49335\tvalid_1's rmse: 1.59103\n",
      "[123]\ttraining's rmse: 1.49173\tvalid_1's rmse: 1.59008\n",
      "[124]\ttraining's rmse: 1.49021\tvalid_1's rmse: 1.58912\n",
      "[125]\ttraining's rmse: 1.48865\tvalid_1's rmse: 1.58828\n",
      "[126]\ttraining's rmse: 1.48708\tvalid_1's rmse: 1.58743\n",
      "[127]\ttraining's rmse: 1.4856\tvalid_1's rmse: 1.58643\n",
      "[128]\ttraining's rmse: 1.48406\tvalid_1's rmse: 1.58577\n",
      "[129]\ttraining's rmse: 1.4825\tvalid_1's rmse: 1.58491\n",
      "[130]\ttraining's rmse: 1.48099\tvalid_1's rmse: 1.58382\n",
      "[131]\ttraining's rmse: 1.47946\tvalid_1's rmse: 1.58301\n",
      "[132]\ttraining's rmse: 1.47794\tvalid_1's rmse: 1.58234\n",
      "[133]\ttraining's rmse: 1.47644\tvalid_1's rmse: 1.58136\n",
      "[134]\ttraining's rmse: 1.47502\tvalid_1's rmse: 1.58065\n",
      "[135]\ttraining's rmse: 1.47359\tvalid_1's rmse: 1.57958\n",
      "[136]\ttraining's rmse: 1.47211\tvalid_1's rmse: 1.57882\n",
      "[137]\ttraining's rmse: 1.47064\tvalid_1's rmse: 1.57786\n",
      "[138]\ttraining's rmse: 1.4692\tvalid_1's rmse: 1.57705\n",
      "[139]\ttraining's rmse: 1.46774\tvalid_1's rmse: 1.57599\n",
      "[140]\ttraining's rmse: 1.46626\tvalid_1's rmse: 1.57511\n",
      "[141]\ttraining's rmse: 1.46474\tvalid_1's rmse: 1.57423\n",
      "[142]\ttraining's rmse: 1.46325\tvalid_1's rmse: 1.57333\n",
      "[143]\ttraining's rmse: 1.46185\tvalid_1's rmse: 1.57266\n",
      "[144]\ttraining's rmse: 1.46046\tvalid_1's rmse: 1.57197\n",
      "[145]\ttraining's rmse: 1.45897\tvalid_1's rmse: 1.57105\n",
      "[146]\ttraining's rmse: 1.45749\tvalid_1's rmse: 1.57031\n",
      "[147]\ttraining's rmse: 1.45607\tvalid_1's rmse: 1.56936\n",
      "[148]\ttraining's rmse: 1.45472\tvalid_1's rmse: 1.56845\n",
      "[149]\ttraining's rmse: 1.45331\tvalid_1's rmse: 1.56754\n",
      "[150]\ttraining's rmse: 1.45193\tvalid_1's rmse: 1.56681\n",
      "[151]\ttraining's rmse: 1.45047\tvalid_1's rmse: 1.56583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[152]\ttraining's rmse: 1.44913\tvalid_1's rmse: 1.56519\n",
      "[153]\ttraining's rmse: 1.44768\tvalid_1's rmse: 1.56448\n",
      "[154]\ttraining's rmse: 1.4463\tvalid_1's rmse: 1.5636\n",
      "[155]\ttraining's rmse: 1.44496\tvalid_1's rmse: 1.56288\n",
      "[156]\ttraining's rmse: 1.4436\tvalid_1's rmse: 1.56192\n",
      "[157]\ttraining's rmse: 1.44217\tvalid_1's rmse: 1.561\n",
      "[158]\ttraining's rmse: 1.44083\tvalid_1's rmse: 1.56012\n",
      "[159]\ttraining's rmse: 1.43934\tvalid_1's rmse: 1.55921\n",
      "[160]\ttraining's rmse: 1.43803\tvalid_1's rmse: 1.55837\n",
      "[161]\ttraining's rmse: 1.43671\tvalid_1's rmse: 1.55754\n",
      "[162]\ttraining's rmse: 1.43529\tvalid_1's rmse: 1.55671\n",
      "[163]\ttraining's rmse: 1.43397\tvalid_1's rmse: 1.5559\n",
      "[164]\ttraining's rmse: 1.43261\tvalid_1's rmse: 1.5552\n",
      "[165]\ttraining's rmse: 1.43124\tvalid_1's rmse: 1.55436\n",
      "[166]\ttraining's rmse: 1.4299\tvalid_1's rmse: 1.55365\n",
      "[167]\ttraining's rmse: 1.42855\tvalid_1's rmse: 1.55257\n",
      "[168]\ttraining's rmse: 1.42721\tvalid_1's rmse: 1.5519\n",
      "[169]\ttraining's rmse: 1.42585\tvalid_1's rmse: 1.55128\n",
      "[170]\ttraining's rmse: 1.42451\tvalid_1's rmse: 1.55061\n",
      "[171]\ttraining's rmse: 1.4231\tvalid_1's rmse: 1.54984\n",
      "[172]\ttraining's rmse: 1.42174\tvalid_1's rmse: 1.54908\n",
      "[173]\ttraining's rmse: 1.42045\tvalid_1's rmse: 1.54831\n",
      "[174]\ttraining's rmse: 1.41912\tvalid_1's rmse: 1.54752\n",
      "[175]\ttraining's rmse: 1.4178\tvalid_1's rmse: 1.54676\n",
      "[176]\ttraining's rmse: 1.41648\tvalid_1's rmse: 1.54613\n",
      "[177]\ttraining's rmse: 1.41517\tvalid_1's rmse: 1.54541\n",
      "[178]\ttraining's rmse: 1.41382\tvalid_1's rmse: 1.54478\n",
      "[179]\ttraining's rmse: 1.41253\tvalid_1's rmse: 1.5441\n",
      "[180]\ttraining's rmse: 1.4112\tvalid_1's rmse: 1.54336\n",
      "[181]\ttraining's rmse: 1.40993\tvalid_1's rmse: 1.54274\n",
      "[182]\ttraining's rmse: 1.40867\tvalid_1's rmse: 1.54204\n",
      "[183]\ttraining's rmse: 1.40741\tvalid_1's rmse: 1.54142\n",
      "[184]\ttraining's rmse: 1.40613\tvalid_1's rmse: 1.54075\n",
      "[185]\ttraining's rmse: 1.40484\tvalid_1's rmse: 1.54008\n",
      "[186]\ttraining's rmse: 1.40357\tvalid_1's rmse: 1.53934\n",
      "[187]\ttraining's rmse: 1.4023\tvalid_1's rmse: 1.53866\n",
      "[188]\ttraining's rmse: 1.40099\tvalid_1's rmse: 1.53791\n",
      "[189]\ttraining's rmse: 1.3997\tvalid_1's rmse: 1.5371\n",
      "[190]\ttraining's rmse: 1.39837\tvalid_1's rmse: 1.53647\n",
      "[191]\ttraining's rmse: 1.39713\tvalid_1's rmse: 1.53584\n",
      "[192]\ttraining's rmse: 1.39589\tvalid_1's rmse: 1.53513\n",
      "[193]\ttraining's rmse: 1.39462\tvalid_1's rmse: 1.53445\n",
      "[194]\ttraining's rmse: 1.39344\tvalid_1's rmse: 1.53398\n",
      "[195]\ttraining's rmse: 1.39219\tvalid_1's rmse: 1.53342\n",
      "[196]\ttraining's rmse: 1.39092\tvalid_1's rmse: 1.53261\n",
      "[197]\ttraining's rmse: 1.38962\tvalid_1's rmse: 1.53194\n",
      "[198]\ttraining's rmse: 1.38832\tvalid_1's rmse: 1.53112\n",
      "[199]\ttraining's rmse: 1.3871\tvalid_1's rmse: 1.53055\n",
      "[200]\ttraining's rmse: 1.38583\tvalid_1's rmse: 1.52975\n",
      "[201]\ttraining's rmse: 1.38466\tvalid_1's rmse: 1.52932\n",
      "[202]\ttraining's rmse: 1.38347\tvalid_1's rmse: 1.5288\n",
      "[203]\ttraining's rmse: 1.38228\tvalid_1's rmse: 1.52808\n",
      "[204]\ttraining's rmse: 1.38112\tvalid_1's rmse: 1.52749\n",
      "[205]\ttraining's rmse: 1.37992\tvalid_1's rmse: 1.52676\n",
      "[206]\ttraining's rmse: 1.3787\tvalid_1's rmse: 1.52609\n",
      "[207]\ttraining's rmse: 1.37753\tvalid_1's rmse: 1.52556\n",
      "[208]\ttraining's rmse: 1.37638\tvalid_1's rmse: 1.52499\n",
      "[209]\ttraining's rmse: 1.37517\tvalid_1's rmse: 1.52419\n",
      "[210]\ttraining's rmse: 1.37398\tvalid_1's rmse: 1.52377\n",
      "[211]\ttraining's rmse: 1.37278\tvalid_1's rmse: 1.52314\n",
      "[212]\ttraining's rmse: 1.3716\tvalid_1's rmse: 1.52273\n",
      "[213]\ttraining's rmse: 1.37044\tvalid_1's rmse: 1.52213\n",
      "[214]\ttraining's rmse: 1.36924\tvalid_1's rmse: 1.52155\n",
      "[215]\ttraining's rmse: 1.36807\tvalid_1's rmse: 1.52104\n",
      "[216]\ttraining's rmse: 1.36688\tvalid_1's rmse: 1.52044\n",
      "[217]\ttraining's rmse: 1.36577\tvalid_1's rmse: 1.51978\n",
      "[218]\ttraining's rmse: 1.36461\tvalid_1's rmse: 1.51927\n",
      "[219]\ttraining's rmse: 1.36345\tvalid_1's rmse: 1.51867\n",
      "[220]\ttraining's rmse: 1.36229\tvalid_1's rmse: 1.51808\n",
      "[221]\ttraining's rmse: 1.36112\tvalid_1's rmse: 1.51753\n",
      "[222]\ttraining's rmse: 1.35995\tvalid_1's rmse: 1.5169\n",
      "[223]\ttraining's rmse: 1.3588\tvalid_1's rmse: 1.5161\n",
      "[224]\ttraining's rmse: 1.35762\tvalid_1's rmse: 1.5155\n",
      "[225]\ttraining's rmse: 1.35647\tvalid_1's rmse: 1.51495\n",
      "[226]\ttraining's rmse: 1.35538\tvalid_1's rmse: 1.51436\n",
      "[227]\ttraining's rmse: 1.35422\tvalid_1's rmse: 1.51389\n",
      "[228]\ttraining's rmse: 1.35311\tvalid_1's rmse: 1.51333\n",
      "[229]\ttraining's rmse: 1.35202\tvalid_1's rmse: 1.51278\n",
      "[230]\ttraining's rmse: 1.35091\tvalid_1's rmse: 1.51224\n",
      "[231]\ttraining's rmse: 1.34974\tvalid_1's rmse: 1.51158\n",
      "[232]\ttraining's rmse: 1.34853\tvalid_1's rmse: 1.51084\n",
      "[233]\ttraining's rmse: 1.3474\tvalid_1's rmse: 1.51038\n",
      "[234]\ttraining's rmse: 1.34631\tvalid_1's rmse: 1.50982\n",
      "[235]\ttraining's rmse: 1.34521\tvalid_1's rmse: 1.50932\n",
      "[236]\ttraining's rmse: 1.34405\tvalid_1's rmse: 1.50877\n",
      "[237]\ttraining's rmse: 1.34298\tvalid_1's rmse: 1.50807\n",
      "[238]\ttraining's rmse: 1.34192\tvalid_1's rmse: 1.50763\n",
      "[239]\ttraining's rmse: 1.34083\tvalid_1's rmse: 1.50727\n",
      "[240]\ttraining's rmse: 1.33974\tvalid_1's rmse: 1.50677\n",
      "[241]\ttraining's rmse: 1.33869\tvalid_1's rmse: 1.50622\n",
      "[242]\ttraining's rmse: 1.33761\tvalid_1's rmse: 1.50568\n",
      "[243]\ttraining's rmse: 1.33653\tvalid_1's rmse: 1.50529\n",
      "[244]\ttraining's rmse: 1.33549\tvalid_1's rmse: 1.50486\n",
      "[245]\ttraining's rmse: 1.33442\tvalid_1's rmse: 1.50432\n",
      "[246]\ttraining's rmse: 1.33337\tvalid_1's rmse: 1.50401\n",
      "[247]\ttraining's rmse: 1.33234\tvalid_1's rmse: 1.50354\n",
      "[248]\ttraining's rmse: 1.33127\tvalid_1's rmse: 1.50296\n",
      "[249]\ttraining's rmse: 1.33021\tvalid_1's rmse: 1.5024\n",
      "[250]\ttraining's rmse: 1.32915\tvalid_1's rmse: 1.50191\n",
      "[251]\ttraining's rmse: 1.3281\tvalid_1's rmse: 1.50137\n",
      "[252]\ttraining's rmse: 1.3271\tvalid_1's rmse: 1.50092\n",
      "[253]\ttraining's rmse: 1.32612\tvalid_1's rmse: 1.50048\n",
      "[254]\ttraining's rmse: 1.32511\tvalid_1's rmse: 1.49992\n",
      "[255]\ttraining's rmse: 1.32406\tvalid_1's rmse: 1.49933\n",
      "[256]\ttraining's rmse: 1.32302\tvalid_1's rmse: 1.49874\n",
      "[257]\ttraining's rmse: 1.32203\tvalid_1's rmse: 1.49821\n",
      "[258]\ttraining's rmse: 1.32097\tvalid_1's rmse: 1.49769\n",
      "[259]\ttraining's rmse: 1.31997\tvalid_1's rmse: 1.49719\n",
      "[260]\ttraining's rmse: 1.31895\tvalid_1's rmse: 1.49679\n",
      "[261]\ttraining's rmse: 1.31795\tvalid_1's rmse: 1.49636\n",
      "[262]\ttraining's rmse: 1.31694\tvalid_1's rmse: 1.49579\n",
      "[263]\ttraining's rmse: 1.316\tvalid_1's rmse: 1.49534\n",
      "[264]\ttraining's rmse: 1.31498\tvalid_1's rmse: 1.49484\n",
      "[265]\ttraining's rmse: 1.31395\tvalid_1's rmse: 1.49445\n",
      "[266]\ttraining's rmse: 1.31299\tvalid_1's rmse: 1.49399\n",
      "[267]\ttraining's rmse: 1.31197\tvalid_1's rmse: 1.49377\n",
      "[268]\ttraining's rmse: 1.31097\tvalid_1's rmse: 1.49338\n",
      "[269]\ttraining's rmse: 1.31001\tvalid_1's rmse: 1.49309\n",
      "[270]\ttraining's rmse: 1.30898\tvalid_1's rmse: 1.49266\n",
      "[271]\ttraining's rmse: 1.30798\tvalid_1's rmse: 1.4922\n",
      "[272]\ttraining's rmse: 1.30704\tvalid_1's rmse: 1.49171\n",
      "[273]\ttraining's rmse: 1.30607\tvalid_1's rmse: 1.4913\n",
      "[274]\ttraining's rmse: 1.30513\tvalid_1's rmse: 1.49092\n",
      "[275]\ttraining's rmse: 1.30415\tvalid_1's rmse: 1.49037\n",
      "[276]\ttraining's rmse: 1.3032\tvalid_1's rmse: 1.49017\n",
      "[277]\ttraining's rmse: 1.30217\tvalid_1's rmse: 1.48966\n",
      "[278]\ttraining's rmse: 1.30127\tvalid_1's rmse: 1.48935\n",
      "[279]\ttraining's rmse: 1.30031\tvalid_1's rmse: 1.48886\n",
      "[280]\ttraining's rmse: 1.29933\tvalid_1's rmse: 1.48845\n",
      "[281]\ttraining's rmse: 1.29838\tvalid_1's rmse: 1.48807\n",
      "[282]\ttraining's rmse: 1.29744\tvalid_1's rmse: 1.48771\n",
      "[283]\ttraining's rmse: 1.29646\tvalid_1's rmse: 1.48723\n",
      "[284]\ttraining's rmse: 1.29554\tvalid_1's rmse: 1.48679\n",
      "[285]\ttraining's rmse: 1.29462\tvalid_1's rmse: 1.48629\n",
      "[286]\ttraining's rmse: 1.29366\tvalid_1's rmse: 1.48596\n",
      "[287]\ttraining's rmse: 1.29269\tvalid_1's rmse: 1.48556\n",
      "[288]\ttraining's rmse: 1.29171\tvalid_1's rmse: 1.48509\n",
      "[289]\ttraining's rmse: 1.29078\tvalid_1's rmse: 1.48464\n",
      "[290]\ttraining's rmse: 1.28989\tvalid_1's rmse: 1.48415\n",
      "[291]\ttraining's rmse: 1.28901\tvalid_1's rmse: 1.48382\n",
      "[292]\ttraining's rmse: 1.2881\tvalid_1's rmse: 1.4836\n",
      "[293]\ttraining's rmse: 1.28721\tvalid_1's rmse: 1.48327\n",
      "[294]\ttraining's rmse: 1.28631\tvalid_1's rmse: 1.48281\n",
      "[295]\ttraining's rmse: 1.28539\tvalid_1's rmse: 1.48254\n",
      "[296]\ttraining's rmse: 1.28448\tvalid_1's rmse: 1.48211\n",
      "[297]\ttraining's rmse: 1.28357\tvalid_1's rmse: 1.48177\n",
      "[298]\ttraining's rmse: 1.28262\tvalid_1's rmse: 1.48141\n",
      "[299]\ttraining's rmse: 1.28178\tvalid_1's rmse: 1.48093\n",
      "[300]\ttraining's rmse: 1.28084\tvalid_1's rmse: 1.48037\n",
      "[301]\ttraining's rmse: 1.27997\tvalid_1's rmse: 1.48004\n",
      "[302]\ttraining's rmse: 1.27907\tvalid_1's rmse: 1.47959\n",
      "[303]\ttraining's rmse: 1.27818\tvalid_1's rmse: 1.47924\n",
      "[304]\ttraining's rmse: 1.27731\tvalid_1's rmse: 1.47892\n",
      "[305]\ttraining's rmse: 1.27644\tvalid_1's rmse: 1.47867\n",
      "[306]\ttraining's rmse: 1.27552\tvalid_1's rmse: 1.47836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[307]\ttraining's rmse: 1.27463\tvalid_1's rmse: 1.47796\n",
      "[308]\ttraining's rmse: 1.27373\tvalid_1's rmse: 1.47773\n",
      "[309]\ttraining's rmse: 1.27288\tvalid_1's rmse: 1.47745\n",
      "[310]\ttraining's rmse: 1.272\tvalid_1's rmse: 1.47695\n",
      "[311]\ttraining's rmse: 1.27103\tvalid_1's rmse: 1.47647\n",
      "[312]\ttraining's rmse: 1.27016\tvalid_1's rmse: 1.47622\n",
      "[313]\ttraining's rmse: 1.26931\tvalid_1's rmse: 1.47591\n",
      "[314]\ttraining's rmse: 1.26844\tvalid_1's rmse: 1.47556\n",
      "[315]\ttraining's rmse: 1.26754\tvalid_1's rmse: 1.4753\n",
      "[316]\ttraining's rmse: 1.26666\tvalid_1's rmse: 1.47506\n",
      "[317]\ttraining's rmse: 1.2658\tvalid_1's rmse: 1.47465\n",
      "[318]\ttraining's rmse: 1.26492\tvalid_1's rmse: 1.47434\n",
      "[319]\ttraining's rmse: 1.26406\tvalid_1's rmse: 1.47408\n",
      "[320]\ttraining's rmse: 1.26318\tvalid_1's rmse: 1.47373\n",
      "[321]\ttraining's rmse: 1.26236\tvalid_1's rmse: 1.47319\n",
      "[322]\ttraining's rmse: 1.26154\tvalid_1's rmse: 1.47285\n",
      "[323]\ttraining's rmse: 1.26066\tvalid_1's rmse: 1.47253\n",
      "[324]\ttraining's rmse: 1.25975\tvalid_1's rmse: 1.47218\n",
      "[325]\ttraining's rmse: 1.25889\tvalid_1's rmse: 1.47188\n",
      "[326]\ttraining's rmse: 1.25809\tvalid_1's rmse: 1.47164\n",
      "[327]\ttraining's rmse: 1.25718\tvalid_1's rmse: 1.4713\n",
      "[328]\ttraining's rmse: 1.25635\tvalid_1's rmse: 1.47089\n",
      "[329]\ttraining's rmse: 1.25549\tvalid_1's rmse: 1.47071\n",
      "[330]\ttraining's rmse: 1.25461\tvalid_1's rmse: 1.47043\n",
      "[331]\ttraining's rmse: 1.2538\tvalid_1's rmse: 1.4702\n",
      "[332]\ttraining's rmse: 1.25299\tvalid_1's rmse: 1.46987\n",
      "[333]\ttraining's rmse: 1.25215\tvalid_1's rmse: 1.46959\n",
      "[334]\ttraining's rmse: 1.25129\tvalid_1's rmse: 1.4692\n",
      "[335]\ttraining's rmse: 1.25049\tvalid_1's rmse: 1.46894\n",
      "[336]\ttraining's rmse: 1.24964\tvalid_1's rmse: 1.46866\n",
      "[337]\ttraining's rmse: 1.24877\tvalid_1's rmse: 1.46833\n",
      "[338]\ttraining's rmse: 1.24798\tvalid_1's rmse: 1.4682\n",
      "[339]\ttraining's rmse: 1.24714\tvalid_1's rmse: 1.46779\n",
      "[340]\ttraining's rmse: 1.24629\tvalid_1's rmse: 1.46747\n",
      "[341]\ttraining's rmse: 1.24542\tvalid_1's rmse: 1.46711\n",
      "[342]\ttraining's rmse: 1.24463\tvalid_1's rmse: 1.46694\n",
      "[343]\ttraining's rmse: 1.24378\tvalid_1's rmse: 1.46672\n",
      "[344]\ttraining's rmse: 1.24299\tvalid_1's rmse: 1.46649\n",
      "[345]\ttraining's rmse: 1.24214\tvalid_1's rmse: 1.4661\n",
      "[346]\ttraining's rmse: 1.24132\tvalid_1's rmse: 1.46581\n",
      "[347]\ttraining's rmse: 1.2405\tvalid_1's rmse: 1.46559\n",
      "[348]\ttraining's rmse: 1.23969\tvalid_1's rmse: 1.46541\n",
      "[349]\ttraining's rmse: 1.23886\tvalid_1's rmse: 1.4651\n",
      "[350]\ttraining's rmse: 1.23805\tvalid_1's rmse: 1.46492\n",
      "[351]\ttraining's rmse: 1.23723\tvalid_1's rmse: 1.4647\n",
      "[352]\ttraining's rmse: 1.23643\tvalid_1's rmse: 1.46439\n",
      "[353]\ttraining's rmse: 1.23563\tvalid_1's rmse: 1.46403\n",
      "[354]\ttraining's rmse: 1.23487\tvalid_1's rmse: 1.4638\n",
      "[355]\ttraining's rmse: 1.2341\tvalid_1's rmse: 1.46369\n",
      "[356]\ttraining's rmse: 1.23334\tvalid_1's rmse: 1.46358\n",
      "[357]\ttraining's rmse: 1.23256\tvalid_1's rmse: 1.46327\n",
      "[358]\ttraining's rmse: 1.23182\tvalid_1's rmse: 1.46311\n",
      "[359]\ttraining's rmse: 1.23104\tvalid_1's rmse: 1.46283\n",
      "[360]\ttraining's rmse: 1.23024\tvalid_1's rmse: 1.46258\n",
      "[361]\ttraining's rmse: 1.22948\tvalid_1's rmse: 1.46241\n",
      "[362]\ttraining's rmse: 1.2287\tvalid_1's rmse: 1.4621\n",
      "[363]\ttraining's rmse: 1.22791\tvalid_1's rmse: 1.46189\n",
      "[364]\ttraining's rmse: 1.22719\tvalid_1's rmse: 1.46175\n",
      "[365]\ttraining's rmse: 1.22642\tvalid_1's rmse: 1.4615\n",
      "[366]\ttraining's rmse: 1.22568\tvalid_1's rmse: 1.46126\n",
      "[367]\ttraining's rmse: 1.22489\tvalid_1's rmse: 1.461\n",
      "[368]\ttraining's rmse: 1.22407\tvalid_1's rmse: 1.46061\n",
      "[369]\ttraining's rmse: 1.22329\tvalid_1's rmse: 1.46033\n",
      "[370]\ttraining's rmse: 1.22249\tvalid_1's rmse: 1.46008\n",
      "[371]\ttraining's rmse: 1.22176\tvalid_1's rmse: 1.45982\n",
      "[372]\ttraining's rmse: 1.22101\tvalid_1's rmse: 1.45943\n",
      "[373]\ttraining's rmse: 1.22025\tvalid_1's rmse: 1.4593\n",
      "[374]\ttraining's rmse: 1.21946\tvalid_1's rmse: 1.45907\n",
      "[375]\ttraining's rmse: 1.21867\tvalid_1's rmse: 1.45884\n",
      "[376]\ttraining's rmse: 1.2179\tvalid_1's rmse: 1.45861\n",
      "[377]\ttraining's rmse: 1.21718\tvalid_1's rmse: 1.45849\n",
      "[378]\ttraining's rmse: 1.21643\tvalid_1's rmse: 1.4582\n",
      "[379]\ttraining's rmse: 1.21566\tvalid_1's rmse: 1.45791\n",
      "[380]\ttraining's rmse: 1.21492\tvalid_1's rmse: 1.45767\n",
      "[381]\ttraining's rmse: 1.21414\tvalid_1's rmse: 1.45742\n",
      "[382]\ttraining's rmse: 1.21339\tvalid_1's rmse: 1.45722\n",
      "[383]\ttraining's rmse: 1.2126\tvalid_1's rmse: 1.45692\n",
      "[384]\ttraining's rmse: 1.21187\tvalid_1's rmse: 1.45673\n",
      "[385]\ttraining's rmse: 1.21116\tvalid_1's rmse: 1.45653\n",
      "[386]\ttraining's rmse: 1.21041\tvalid_1's rmse: 1.4563\n",
      "[387]\ttraining's rmse: 1.2096\tvalid_1's rmse: 1.45628\n",
      "[388]\ttraining's rmse: 1.20883\tvalid_1's rmse: 1.45604\n",
      "[389]\ttraining's rmse: 1.20812\tvalid_1's rmse: 1.4558\n",
      "[390]\ttraining's rmse: 1.20737\tvalid_1's rmse: 1.45564\n",
      "[391]\ttraining's rmse: 1.2066\tvalid_1's rmse: 1.45537\n",
      "[392]\ttraining's rmse: 1.20586\tvalid_1's rmse: 1.45513\n",
      "[393]\ttraining's rmse: 1.20507\tvalid_1's rmse: 1.45485\n",
      "[394]\ttraining's rmse: 1.20432\tvalid_1's rmse: 1.45465\n",
      "[395]\ttraining's rmse: 1.20354\tvalid_1's rmse: 1.45442\n",
      "[396]\ttraining's rmse: 1.20282\tvalid_1's rmse: 1.45435\n",
      "[397]\ttraining's rmse: 1.20212\tvalid_1's rmse: 1.454\n",
      "[398]\ttraining's rmse: 1.20141\tvalid_1's rmse: 1.45391\n",
      "[399]\ttraining's rmse: 1.20066\tvalid_1's rmse: 1.45372\n",
      "[400]\ttraining's rmse: 1.19994\tvalid_1's rmse: 1.45367\n",
      "[401]\ttraining's rmse: 1.19923\tvalid_1's rmse: 1.4535\n",
      "[402]\ttraining's rmse: 1.19847\tvalid_1's rmse: 1.45321\n",
      "[403]\ttraining's rmse: 1.19771\tvalid_1's rmse: 1.45299\n",
      "[404]\ttraining's rmse: 1.197\tvalid_1's rmse: 1.45276\n",
      "[405]\ttraining's rmse: 1.19629\tvalid_1's rmse: 1.45264\n",
      "[406]\ttraining's rmse: 1.19559\tvalid_1's rmse: 1.45247\n",
      "[407]\ttraining's rmse: 1.19488\tvalid_1's rmse: 1.45228\n",
      "[408]\ttraining's rmse: 1.19415\tvalid_1's rmse: 1.45204\n",
      "[409]\ttraining's rmse: 1.19345\tvalid_1's rmse: 1.45182\n",
      "[410]\ttraining's rmse: 1.19277\tvalid_1's rmse: 1.45171\n",
      "[411]\ttraining's rmse: 1.19206\tvalid_1's rmse: 1.45146\n",
      "[412]\ttraining's rmse: 1.19134\tvalid_1's rmse: 1.45127\n",
      "[413]\ttraining's rmse: 1.19067\tvalid_1's rmse: 1.45115\n",
      "[414]\ttraining's rmse: 1.18995\tvalid_1's rmse: 1.45099\n",
      "[415]\ttraining's rmse: 1.18925\tvalid_1's rmse: 1.45078\n",
      "[416]\ttraining's rmse: 1.18853\tvalid_1's rmse: 1.4505\n",
      "[417]\ttraining's rmse: 1.18782\tvalid_1's rmse: 1.45033\n",
      "[418]\ttraining's rmse: 1.18713\tvalid_1's rmse: 1.45017\n",
      "[419]\ttraining's rmse: 1.18645\tvalid_1's rmse: 1.45003\n",
      "[420]\ttraining's rmse: 1.1858\tvalid_1's rmse: 1.44983\n",
      "[421]\ttraining's rmse: 1.18512\tvalid_1's rmse: 1.44965\n",
      "[422]\ttraining's rmse: 1.18439\tvalid_1's rmse: 1.44948\n",
      "[423]\ttraining's rmse: 1.18368\tvalid_1's rmse: 1.44932\n",
      "[424]\ttraining's rmse: 1.18299\tvalid_1's rmse: 1.44912\n",
      "[425]\ttraining's rmse: 1.18234\tvalid_1's rmse: 1.44902\n",
      "[426]\ttraining's rmse: 1.18164\tvalid_1's rmse: 1.44896\n",
      "[427]\ttraining's rmse: 1.18095\tvalid_1's rmse: 1.44872\n",
      "[428]\ttraining's rmse: 1.18029\tvalid_1's rmse: 1.44855\n",
      "[429]\ttraining's rmse: 1.17962\tvalid_1's rmse: 1.4483\n",
      "[430]\ttraining's rmse: 1.17896\tvalid_1's rmse: 1.44807\n",
      "[431]\ttraining's rmse: 1.17825\tvalid_1's rmse: 1.44804\n",
      "[432]\ttraining's rmse: 1.17762\tvalid_1's rmse: 1.44783\n",
      "[433]\ttraining's rmse: 1.17694\tvalid_1's rmse: 1.4477\n",
      "[434]\ttraining's rmse: 1.17627\tvalid_1's rmse: 1.44762\n",
      "[435]\ttraining's rmse: 1.1756\tvalid_1's rmse: 1.44746\n",
      "[436]\ttraining's rmse: 1.17495\tvalid_1's rmse: 1.44723\n",
      "[437]\ttraining's rmse: 1.17429\tvalid_1's rmse: 1.44707\n",
      "[438]\ttraining's rmse: 1.17359\tvalid_1's rmse: 1.44696\n",
      "[439]\ttraining's rmse: 1.17296\tvalid_1's rmse: 1.44687\n",
      "[440]\ttraining's rmse: 1.17227\tvalid_1's rmse: 1.44657\n",
      "[441]\ttraining's rmse: 1.1716\tvalid_1's rmse: 1.44634\n",
      "[442]\ttraining's rmse: 1.17094\tvalid_1's rmse: 1.44616\n",
      "[443]\ttraining's rmse: 1.17023\tvalid_1's rmse: 1.44589\n",
      "[444]\ttraining's rmse: 1.1696\tvalid_1's rmse: 1.44577\n",
      "[445]\ttraining's rmse: 1.16894\tvalid_1's rmse: 1.44549\n",
      "[446]\ttraining's rmse: 1.16829\tvalid_1's rmse: 1.44537\n",
      "[447]\ttraining's rmse: 1.16762\tvalid_1's rmse: 1.44526\n",
      "[448]\ttraining's rmse: 1.16695\tvalid_1's rmse: 1.44496\n",
      "[449]\ttraining's rmse: 1.16632\tvalid_1's rmse: 1.44479\n",
      "[450]\ttraining's rmse: 1.16565\tvalid_1's rmse: 1.44464\n",
      "[451]\ttraining's rmse: 1.16501\tvalid_1's rmse: 1.44452\n",
      "[452]\ttraining's rmse: 1.16436\tvalid_1's rmse: 1.44436\n",
      "[453]\ttraining's rmse: 1.16374\tvalid_1's rmse: 1.44437\n",
      "[454]\ttraining's rmse: 1.16316\tvalid_1's rmse: 1.44417\n",
      "[455]\ttraining's rmse: 1.16254\tvalid_1's rmse: 1.44401\n",
      "[456]\ttraining's rmse: 1.16186\tvalid_1's rmse: 1.44386\n",
      "[457]\ttraining's rmse: 1.16119\tvalid_1's rmse: 1.44368\n",
      "[458]\ttraining's rmse: 1.16057\tvalid_1's rmse: 1.44357\n",
      "[459]\ttraining's rmse: 1.1599\tvalid_1's rmse: 1.44346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[460]\ttraining's rmse: 1.15922\tvalid_1's rmse: 1.44326\n",
      "[461]\ttraining's rmse: 1.1586\tvalid_1's rmse: 1.44303\n",
      "[462]\ttraining's rmse: 1.15796\tvalid_1's rmse: 1.443\n",
      "[463]\ttraining's rmse: 1.15734\tvalid_1's rmse: 1.44285\n",
      "[464]\ttraining's rmse: 1.15669\tvalid_1's rmse: 1.44267\n",
      "[465]\ttraining's rmse: 1.15603\tvalid_1's rmse: 1.44246\n",
      "[466]\ttraining's rmse: 1.15541\tvalid_1's rmse: 1.44229\n",
      "[467]\ttraining's rmse: 1.15476\tvalid_1's rmse: 1.44223\n",
      "[468]\ttraining's rmse: 1.15415\tvalid_1's rmse: 1.44206\n",
      "[469]\ttraining's rmse: 1.1535\tvalid_1's rmse: 1.44189\n",
      "[470]\ttraining's rmse: 1.15285\tvalid_1's rmse: 1.44184\n",
      "[471]\ttraining's rmse: 1.15217\tvalid_1's rmse: 1.44172\n",
      "[472]\ttraining's rmse: 1.15154\tvalid_1's rmse: 1.44152\n",
      "[473]\ttraining's rmse: 1.15088\tvalid_1's rmse: 1.44138\n",
      "[474]\ttraining's rmse: 1.15026\tvalid_1's rmse: 1.44133\n",
      "[475]\ttraining's rmse: 1.14965\tvalid_1's rmse: 1.44116\n",
      "[476]\ttraining's rmse: 1.14901\tvalid_1's rmse: 1.44108\n",
      "[477]\ttraining's rmse: 1.14841\tvalid_1's rmse: 1.44095\n",
      "[478]\ttraining's rmse: 1.14776\tvalid_1's rmse: 1.44084\n",
      "[479]\ttraining's rmse: 1.14716\tvalid_1's rmse: 1.44064\n",
      "[480]\ttraining's rmse: 1.14656\tvalid_1's rmse: 1.44068\n",
      "[481]\ttraining's rmse: 1.14595\tvalid_1's rmse: 1.44064\n",
      "[482]\ttraining's rmse: 1.14533\tvalid_1's rmse: 1.44052\n",
      "[483]\ttraining's rmse: 1.14472\tvalid_1's rmse: 1.44038\n",
      "[484]\ttraining's rmse: 1.14409\tvalid_1's rmse: 1.44029\n",
      "[485]\ttraining's rmse: 1.14345\tvalid_1's rmse: 1.44021\n",
      "[486]\ttraining's rmse: 1.14283\tvalid_1's rmse: 1.44007\n",
      "[487]\ttraining's rmse: 1.14225\tvalid_1's rmse: 1.43999\n",
      "[488]\ttraining's rmse: 1.14164\tvalid_1's rmse: 1.43982\n",
      "[489]\ttraining's rmse: 1.14105\tvalid_1's rmse: 1.43971\n",
      "[490]\ttraining's rmse: 1.14043\tvalid_1's rmse: 1.43954\n",
      "[491]\ttraining's rmse: 1.13984\tvalid_1's rmse: 1.43948\n",
      "[492]\ttraining's rmse: 1.13928\tvalid_1's rmse: 1.43929\n",
      "[493]\ttraining's rmse: 1.1387\tvalid_1's rmse: 1.43923\n",
      "[494]\ttraining's rmse: 1.1381\tvalid_1's rmse: 1.43917\n",
      "[495]\ttraining's rmse: 1.13756\tvalid_1's rmse: 1.43914\n",
      "[496]\ttraining's rmse: 1.13695\tvalid_1's rmse: 1.43909\n",
      "[497]\ttraining's rmse: 1.13635\tvalid_1's rmse: 1.43888\n",
      "[498]\ttraining's rmse: 1.13577\tvalid_1's rmse: 1.43881\n",
      "[499]\ttraining's rmse: 1.13516\tvalid_1's rmse: 1.43862\n",
      "[500]\ttraining's rmse: 1.1346\tvalid_1's rmse: 1.43843\n",
      "[501]\ttraining's rmse: 1.13401\tvalid_1's rmse: 1.43839\n",
      "[502]\ttraining's rmse: 1.13344\tvalid_1's rmse: 1.43823\n",
      "[503]\ttraining's rmse: 1.13287\tvalid_1's rmse: 1.43818\n",
      "[504]\ttraining's rmse: 1.13228\tvalid_1's rmse: 1.43795\n",
      "[505]\ttraining's rmse: 1.13168\tvalid_1's rmse: 1.43773\n",
      "[506]\ttraining's rmse: 1.13114\tvalid_1's rmse: 1.4376\n",
      "[507]\ttraining's rmse: 1.13055\tvalid_1's rmse: 1.43747\n",
      "[508]\ttraining's rmse: 1.12999\tvalid_1's rmse: 1.4374\n",
      "[509]\ttraining's rmse: 1.12941\tvalid_1's rmse: 1.43718\n",
      "[510]\ttraining's rmse: 1.1288\tvalid_1's rmse: 1.43697\n",
      "[511]\ttraining's rmse: 1.12819\tvalid_1's rmse: 1.43685\n",
      "[512]\ttraining's rmse: 1.12761\tvalid_1's rmse: 1.43684\n",
      "[513]\ttraining's rmse: 1.12702\tvalid_1's rmse: 1.43673\n",
      "[514]\ttraining's rmse: 1.12647\tvalid_1's rmse: 1.43661\n",
      "[515]\ttraining's rmse: 1.1259\tvalid_1's rmse: 1.43641\n",
      "[516]\ttraining's rmse: 1.12533\tvalid_1's rmse: 1.43629\n",
      "[517]\ttraining's rmse: 1.12475\tvalid_1's rmse: 1.43618\n",
      "[518]\ttraining's rmse: 1.12419\tvalid_1's rmse: 1.43619\n",
      "[519]\ttraining's rmse: 1.12363\tvalid_1's rmse: 1.43609\n",
      "[520]\ttraining's rmse: 1.12308\tvalid_1's rmse: 1.43609\n",
      "[521]\ttraining's rmse: 1.12245\tvalid_1's rmse: 1.43601\n",
      "[522]\ttraining's rmse: 1.12186\tvalid_1's rmse: 1.43587\n",
      "[523]\ttraining's rmse: 1.12128\tvalid_1's rmse: 1.43572\n",
      "[524]\ttraining's rmse: 1.12071\tvalid_1's rmse: 1.43551\n",
      "[525]\ttraining's rmse: 1.12013\tvalid_1's rmse: 1.43554\n",
      "[526]\ttraining's rmse: 1.11959\tvalid_1's rmse: 1.43548\n",
      "[527]\ttraining's rmse: 1.11905\tvalid_1's rmse: 1.43524\n",
      "[528]\ttraining's rmse: 1.1185\tvalid_1's rmse: 1.43513\n",
      "[529]\ttraining's rmse: 1.11796\tvalid_1's rmse: 1.43505\n",
      "[530]\ttraining's rmse: 1.1174\tvalid_1's rmse: 1.43499\n",
      "[531]\ttraining's rmse: 1.11681\tvalid_1's rmse: 1.4349\n",
      "[532]\ttraining's rmse: 1.11628\tvalid_1's rmse: 1.4349\n",
      "[533]\ttraining's rmse: 1.11574\tvalid_1's rmse: 1.43488\n",
      "[534]\ttraining's rmse: 1.1152\tvalid_1's rmse: 1.43478\n",
      "[535]\ttraining's rmse: 1.11461\tvalid_1's rmse: 1.43465\n",
      "[536]\ttraining's rmse: 1.11411\tvalid_1's rmse: 1.43467\n",
      "[537]\ttraining's rmse: 1.11357\tvalid_1's rmse: 1.43464\n",
      "[538]\ttraining's rmse: 1.11303\tvalid_1's rmse: 1.43454\n",
      "[539]\ttraining's rmse: 1.11245\tvalid_1's rmse: 1.43456\n",
      "[540]\ttraining's rmse: 1.11186\tvalid_1's rmse: 1.43438\n",
      "[541]\ttraining's rmse: 1.11133\tvalid_1's rmse: 1.43434\n",
      "[542]\ttraining's rmse: 1.11077\tvalid_1's rmse: 1.43431\n",
      "[543]\ttraining's rmse: 1.11022\tvalid_1's rmse: 1.43436\n",
      "[544]\ttraining's rmse: 1.10966\tvalid_1's rmse: 1.43415\n",
      "[545]\ttraining's rmse: 1.1091\tvalid_1's rmse: 1.43416\n",
      "[546]\ttraining's rmse: 1.10856\tvalid_1's rmse: 1.4341\n",
      "[547]\ttraining's rmse: 1.10802\tvalid_1's rmse: 1.43403\n",
      "[548]\ttraining's rmse: 1.1075\tvalid_1's rmse: 1.43393\n",
      "[549]\ttraining's rmse: 1.10699\tvalid_1's rmse: 1.4339\n",
      "[550]\ttraining's rmse: 1.10647\tvalid_1's rmse: 1.43382\n",
      "[551]\ttraining's rmse: 1.10594\tvalid_1's rmse: 1.43371\n",
      "[552]\ttraining's rmse: 1.10542\tvalid_1's rmse: 1.43371\n",
      "[553]\ttraining's rmse: 1.10484\tvalid_1's rmse: 1.4337\n",
      "[554]\ttraining's rmse: 1.1043\tvalid_1's rmse: 1.43352\n",
      "[555]\ttraining's rmse: 1.1038\tvalid_1's rmse: 1.43344\n",
      "[556]\ttraining's rmse: 1.10325\tvalid_1's rmse: 1.4334\n",
      "[557]\ttraining's rmse: 1.10272\tvalid_1's rmse: 1.43338\n",
      "[558]\ttraining's rmse: 1.10216\tvalid_1's rmse: 1.43328\n",
      "[559]\ttraining's rmse: 1.10162\tvalid_1's rmse: 1.43315\n",
      "[560]\ttraining's rmse: 1.10111\tvalid_1's rmse: 1.43323\n",
      "[561]\ttraining's rmse: 1.10065\tvalid_1's rmse: 1.4332\n",
      "[562]\ttraining's rmse: 1.10009\tvalid_1's rmse: 1.43312\n",
      "[563]\ttraining's rmse: 1.09957\tvalid_1's rmse: 1.43306\n",
      "[564]\ttraining's rmse: 1.09907\tvalid_1's rmse: 1.43293\n",
      "[565]\ttraining's rmse: 1.09857\tvalid_1's rmse: 1.43282\n",
      "[566]\ttraining's rmse: 1.09808\tvalid_1's rmse: 1.43277\n",
      "[567]\ttraining's rmse: 1.09753\tvalid_1's rmse: 1.43276\n",
      "[568]\ttraining's rmse: 1.097\tvalid_1's rmse: 1.43264\n",
      "[569]\ttraining's rmse: 1.09643\tvalid_1's rmse: 1.43255\n",
      "[570]\ttraining's rmse: 1.09589\tvalid_1's rmse: 1.43251\n",
      "[571]\ttraining's rmse: 1.09538\tvalid_1's rmse: 1.4325\n",
      "[572]\ttraining's rmse: 1.09486\tvalid_1's rmse: 1.43256\n",
      "[573]\ttraining's rmse: 1.09434\tvalid_1's rmse: 1.43247\n",
      "[574]\ttraining's rmse: 1.09385\tvalid_1's rmse: 1.43244\n",
      "[575]\ttraining's rmse: 1.09336\tvalid_1's rmse: 1.43233\n",
      "[576]\ttraining's rmse: 1.0929\tvalid_1's rmse: 1.43229\n",
      "[577]\ttraining's rmse: 1.09246\tvalid_1's rmse: 1.43231\n",
      "[578]\ttraining's rmse: 1.09194\tvalid_1's rmse: 1.4323\n",
      "[579]\ttraining's rmse: 1.09142\tvalid_1's rmse: 1.43227\n",
      "[580]\ttraining's rmse: 1.09092\tvalid_1's rmse: 1.43223\n",
      "[581]\ttraining's rmse: 1.09037\tvalid_1's rmse: 1.43215\n",
      "[582]\ttraining's rmse: 1.08987\tvalid_1's rmse: 1.43214\n",
      "[583]\ttraining's rmse: 1.08937\tvalid_1's rmse: 1.43217\n",
      "[584]\ttraining's rmse: 1.08887\tvalid_1's rmse: 1.43206\n",
      "[585]\ttraining's rmse: 1.08835\tvalid_1's rmse: 1.43195\n",
      "[586]\ttraining's rmse: 1.08786\tvalid_1's rmse: 1.43191\n",
      "[587]\ttraining's rmse: 1.08734\tvalid_1's rmse: 1.43182\n",
      "[588]\ttraining's rmse: 1.08688\tvalid_1's rmse: 1.43168\n",
      "[589]\ttraining's rmse: 1.0864\tvalid_1's rmse: 1.43163\n",
      "[590]\ttraining's rmse: 1.08585\tvalid_1's rmse: 1.43156\n",
      "[591]\ttraining's rmse: 1.08535\tvalid_1's rmse: 1.43148\n",
      "[592]\ttraining's rmse: 1.08484\tvalid_1's rmse: 1.43142\n",
      "[593]\ttraining's rmse: 1.08435\tvalid_1's rmse: 1.43129\n",
      "[594]\ttraining's rmse: 1.08386\tvalid_1's rmse: 1.43122\n",
      "[595]\ttraining's rmse: 1.0834\tvalid_1's rmse: 1.43118\n",
      "[596]\ttraining's rmse: 1.08293\tvalid_1's rmse: 1.43109\n",
      "[597]\ttraining's rmse: 1.08246\tvalid_1's rmse: 1.43103\n",
      "[598]\ttraining's rmse: 1.08192\tvalid_1's rmse: 1.43093\n",
      "[599]\ttraining's rmse: 1.08141\tvalid_1's rmse: 1.43094\n",
      "[600]\ttraining's rmse: 1.08093\tvalid_1's rmse: 1.4309\n",
      "[601]\ttraining's rmse: 1.08049\tvalid_1's rmse: 1.43088\n",
      "[602]\ttraining's rmse: 1.07998\tvalid_1's rmse: 1.43092\n",
      "[603]\ttraining's rmse: 1.07949\tvalid_1's rmse: 1.43097\n",
      "[604]\ttraining's rmse: 1.07899\tvalid_1's rmse: 1.43097\n",
      "[605]\ttraining's rmse: 1.07852\tvalid_1's rmse: 1.43092\n",
      "[606]\ttraining's rmse: 1.07806\tvalid_1's rmse: 1.43088\n",
      "[607]\ttraining's rmse: 1.07757\tvalid_1's rmse: 1.43091\n",
      "[608]\ttraining's rmse: 1.07709\tvalid_1's rmse: 1.43085\n",
      "[609]\ttraining's rmse: 1.07663\tvalid_1's rmse: 1.43084\n",
      "[610]\ttraining's rmse: 1.07619\tvalid_1's rmse: 1.43084\n",
      "[611]\ttraining's rmse: 1.07569\tvalid_1's rmse: 1.43078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[612]\ttraining's rmse: 1.07521\tvalid_1's rmse: 1.4308\n",
      "[613]\ttraining's rmse: 1.07475\tvalid_1's rmse: 1.43077\n",
      "[614]\ttraining's rmse: 1.0743\tvalid_1's rmse: 1.43073\n",
      "[615]\ttraining's rmse: 1.07388\tvalid_1's rmse: 1.43075\n",
      "[616]\ttraining's rmse: 1.07339\tvalid_1's rmse: 1.43074\n",
      "[617]\ttraining's rmse: 1.07289\tvalid_1's rmse: 1.43068\n",
      "[618]\ttraining's rmse: 1.07239\tvalid_1's rmse: 1.43058\n",
      "[619]\ttraining's rmse: 1.07192\tvalid_1's rmse: 1.43058\n",
      "[620]\ttraining's rmse: 1.07143\tvalid_1's rmse: 1.43058\n",
      "[621]\ttraining's rmse: 1.07096\tvalid_1's rmse: 1.43057\n",
      "[622]\ttraining's rmse: 1.07051\tvalid_1's rmse: 1.43062\n",
      "[623]\ttraining's rmse: 1.07005\tvalid_1's rmse: 1.43059\n",
      "[624]\ttraining's rmse: 1.0696\tvalid_1's rmse: 1.43051\n",
      "[625]\ttraining's rmse: 1.06914\tvalid_1's rmse: 1.43042\n",
      "[626]\ttraining's rmse: 1.06864\tvalid_1's rmse: 1.43042\n",
      "[627]\ttraining's rmse: 1.06815\tvalid_1's rmse: 1.43038\n",
      "[628]\ttraining's rmse: 1.06765\tvalid_1's rmse: 1.43029\n",
      "[629]\ttraining's rmse: 1.06722\tvalid_1's rmse: 1.43029\n",
      "[630]\ttraining's rmse: 1.06679\tvalid_1's rmse: 1.43021\n",
      "[631]\ttraining's rmse: 1.06633\tvalid_1's rmse: 1.43021\n",
      "[632]\ttraining's rmse: 1.06586\tvalid_1's rmse: 1.43018\n",
      "[633]\ttraining's rmse: 1.06537\tvalid_1's rmse: 1.43013\n",
      "[634]\ttraining's rmse: 1.06487\tvalid_1's rmse: 1.43003\n",
      "[635]\ttraining's rmse: 1.06439\tvalid_1's rmse: 1.43008\n",
      "[636]\ttraining's rmse: 1.06393\tvalid_1's rmse: 1.43006\n",
      "[637]\ttraining's rmse: 1.06349\tvalid_1's rmse: 1.43004\n",
      "[638]\ttraining's rmse: 1.06304\tvalid_1's rmse: 1.42997\n",
      "[639]\ttraining's rmse: 1.06256\tvalid_1's rmse: 1.42998\n",
      "[640]\ttraining's rmse: 1.0621\tvalid_1's rmse: 1.43006\n",
      "[641]\ttraining's rmse: 1.06168\tvalid_1's rmse: 1.43009\n",
      "[642]\ttraining's rmse: 1.06126\tvalid_1's rmse: 1.43011\n",
      "[643]\ttraining's rmse: 1.06078\tvalid_1's rmse: 1.43004\n",
      "[644]\ttraining's rmse: 1.06035\tvalid_1's rmse: 1.43005\n",
      "[645]\ttraining's rmse: 1.05992\tvalid_1's rmse: 1.43017\n",
      "[646]\ttraining's rmse: 1.05941\tvalid_1's rmse: 1.43018\n",
      "[647]\ttraining's rmse: 1.05896\tvalid_1's rmse: 1.43018\n",
      "[648]\ttraining's rmse: 1.05851\tvalid_1's rmse: 1.43018\n",
      "[649]\ttraining's rmse: 1.0581\tvalid_1's rmse: 1.43009\n",
      "[650]\ttraining's rmse: 1.05767\tvalid_1's rmse: 1.42998\n",
      "[651]\ttraining's rmse: 1.05726\tvalid_1's rmse: 1.42995\n",
      "[652]\ttraining's rmse: 1.05683\tvalid_1's rmse: 1.42988\n",
      "[653]\ttraining's rmse: 1.05637\tvalid_1's rmse: 1.42976\n",
      "[654]\ttraining's rmse: 1.05592\tvalid_1's rmse: 1.42976\n",
      "[655]\ttraining's rmse: 1.05547\tvalid_1's rmse: 1.42977\n",
      "[656]\ttraining's rmse: 1.05502\tvalid_1's rmse: 1.42974\n",
      "[657]\ttraining's rmse: 1.05454\tvalid_1's rmse: 1.42969\n",
      "[658]\ttraining's rmse: 1.05412\tvalid_1's rmse: 1.42967\n",
      "[659]\ttraining's rmse: 1.05367\tvalid_1's rmse: 1.42959\n",
      "[660]\ttraining's rmse: 1.05323\tvalid_1's rmse: 1.42971\n",
      "[661]\ttraining's rmse: 1.05276\tvalid_1's rmse: 1.42967\n",
      "[662]\ttraining's rmse: 1.05238\tvalid_1's rmse: 1.42961\n",
      "[663]\ttraining's rmse: 1.05197\tvalid_1's rmse: 1.42959\n",
      "[664]\ttraining's rmse: 1.05156\tvalid_1's rmse: 1.42958\n",
      "[665]\ttraining's rmse: 1.05109\tvalid_1's rmse: 1.42954\n",
      "[666]\ttraining's rmse: 1.05062\tvalid_1's rmse: 1.42949\n",
      "[667]\ttraining's rmse: 1.05018\tvalid_1's rmse: 1.4294\n",
      "[668]\ttraining's rmse: 1.04978\tvalid_1's rmse: 1.42931\n",
      "[669]\ttraining's rmse: 1.04937\tvalid_1's rmse: 1.42924\n",
      "[670]\ttraining's rmse: 1.04895\tvalid_1's rmse: 1.42923\n",
      "[671]\ttraining's rmse: 1.04855\tvalid_1's rmse: 1.42921\n",
      "[672]\ttraining's rmse: 1.04813\tvalid_1's rmse: 1.42922\n",
      "[673]\ttraining's rmse: 1.04769\tvalid_1's rmse: 1.42917\n",
      "[674]\ttraining's rmse: 1.04728\tvalid_1's rmse: 1.42913\n",
      "[675]\ttraining's rmse: 1.04685\tvalid_1's rmse: 1.42906\n",
      "[676]\ttraining's rmse: 1.04641\tvalid_1's rmse: 1.42892\n",
      "[677]\ttraining's rmse: 1.04602\tvalid_1's rmse: 1.42888\n",
      "[678]\ttraining's rmse: 1.0455\tvalid_1's rmse: 1.42879\n",
      "[679]\ttraining's rmse: 1.04505\tvalid_1's rmse: 1.42875\n",
      "[680]\ttraining's rmse: 1.04463\tvalid_1's rmse: 1.42881\n",
      "[681]\ttraining's rmse: 1.04424\tvalid_1's rmse: 1.42878\n",
      "[682]\ttraining's rmse: 1.04386\tvalid_1's rmse: 1.4288\n",
      "[683]\ttraining's rmse: 1.04345\tvalid_1's rmse: 1.42879\n",
      "[684]\ttraining's rmse: 1.04301\tvalid_1's rmse: 1.42878\n",
      "[685]\ttraining's rmse: 1.04259\tvalid_1's rmse: 1.42878\n",
      "[686]\ttraining's rmse: 1.0422\tvalid_1's rmse: 1.42871\n",
      "[687]\ttraining's rmse: 1.04181\tvalid_1's rmse: 1.42871\n",
      "[688]\ttraining's rmse: 1.04137\tvalid_1's rmse: 1.42865\n",
      "[689]\ttraining's rmse: 1.04101\tvalid_1's rmse: 1.42858\n",
      "[690]\ttraining's rmse: 1.04055\tvalid_1's rmse: 1.42855\n",
      "[691]\ttraining's rmse: 1.04015\tvalid_1's rmse: 1.4285\n",
      "[692]\ttraining's rmse: 1.03975\tvalid_1's rmse: 1.42855\n",
      "[693]\ttraining's rmse: 1.03934\tvalid_1's rmse: 1.42855\n",
      "[694]\ttraining's rmse: 1.03896\tvalid_1's rmse: 1.42856\n",
      "[695]\ttraining's rmse: 1.03853\tvalid_1's rmse: 1.42862\n",
      "[696]\ttraining's rmse: 1.03811\tvalid_1's rmse: 1.4286\n",
      "[697]\ttraining's rmse: 1.0377\tvalid_1's rmse: 1.42865\n",
      "[698]\ttraining's rmse: 1.03734\tvalid_1's rmse: 1.42867\n",
      "[699]\ttraining's rmse: 1.03693\tvalid_1's rmse: 1.42875\n",
      "[700]\ttraining's rmse: 1.0365\tvalid_1's rmse: 1.42875\n",
      "[701]\ttraining's rmse: 1.03605\tvalid_1's rmse: 1.42878\n",
      "[702]\ttraining's rmse: 1.03562\tvalid_1's rmse: 1.42861\n",
      "[703]\ttraining's rmse: 1.0352\tvalid_1's rmse: 1.42869\n",
      "[704]\ttraining's rmse: 1.03479\tvalid_1's rmse: 1.42867\n",
      "[705]\ttraining's rmse: 1.03437\tvalid_1's rmse: 1.42862\n",
      "[706]\ttraining's rmse: 1.03396\tvalid_1's rmse: 1.42866\n",
      "[707]\ttraining's rmse: 1.03355\tvalid_1's rmse: 1.4286\n",
      "[708]\ttraining's rmse: 1.0331\tvalid_1's rmse: 1.42859\n",
      "[709]\ttraining's rmse: 1.03271\tvalid_1's rmse: 1.42855\n",
      "[710]\ttraining's rmse: 1.0323\tvalid_1's rmse: 1.42854\n",
      "[711]\ttraining's rmse: 1.03189\tvalid_1's rmse: 1.4285\n",
      "[712]\ttraining's rmse: 1.03153\tvalid_1's rmse: 1.42847\n",
      "[713]\ttraining's rmse: 1.03116\tvalid_1's rmse: 1.42853\n",
      "[714]\ttraining's rmse: 1.03075\tvalid_1's rmse: 1.42848\n",
      "[715]\ttraining's rmse: 1.03027\tvalid_1's rmse: 1.42846\n",
      "[716]\ttraining's rmse: 1.02989\tvalid_1's rmse: 1.42836\n",
      "[717]\ttraining's rmse: 1.02949\tvalid_1's rmse: 1.42835\n",
      "[718]\ttraining's rmse: 1.02908\tvalid_1's rmse: 1.42838\n",
      "[719]\ttraining's rmse: 1.02869\tvalid_1's rmse: 1.42837\n",
      "[720]\ttraining's rmse: 1.02827\tvalid_1's rmse: 1.42841\n",
      "[721]\ttraining's rmse: 1.02784\tvalid_1's rmse: 1.42843\n",
      "[722]\ttraining's rmse: 1.02747\tvalid_1's rmse: 1.42841\n",
      "[723]\ttraining's rmse: 1.02707\tvalid_1's rmse: 1.42841\n",
      "[724]\ttraining's rmse: 1.0267\tvalid_1's rmse: 1.42848\n",
      "[725]\ttraining's rmse: 1.02632\tvalid_1's rmse: 1.42848\n",
      "[726]\ttraining's rmse: 1.02599\tvalid_1's rmse: 1.42846\n",
      "[727]\ttraining's rmse: 1.02561\tvalid_1's rmse: 1.42846\n",
      "[728]\ttraining's rmse: 1.02521\tvalid_1's rmse: 1.42845\n",
      "[729]\ttraining's rmse: 1.02484\tvalid_1's rmse: 1.42841\n",
      "[730]\ttraining's rmse: 1.0244\tvalid_1's rmse: 1.42832\n",
      "[731]\ttraining's rmse: 1.02402\tvalid_1's rmse: 1.42828\n",
      "[732]\ttraining's rmse: 1.02366\tvalid_1's rmse: 1.42832\n",
      "[733]\ttraining's rmse: 1.02325\tvalid_1's rmse: 1.42835\n",
      "[734]\ttraining's rmse: 1.02288\tvalid_1's rmse: 1.42838\n",
      "[735]\ttraining's rmse: 1.02248\tvalid_1's rmse: 1.4284\n",
      "[736]\ttraining's rmse: 1.02207\tvalid_1's rmse: 1.42839\n",
      "[737]\ttraining's rmse: 1.02169\tvalid_1's rmse: 1.42835\n",
      "[738]\ttraining's rmse: 1.02124\tvalid_1's rmse: 1.42834\n",
      "[739]\ttraining's rmse: 1.02087\tvalid_1's rmse: 1.42835\n",
      "[740]\ttraining's rmse: 1.02055\tvalid_1's rmse: 1.42842\n",
      "[741]\ttraining's rmse: 1.02018\tvalid_1's rmse: 1.42841\n",
      "[742]\ttraining's rmse: 1.01981\tvalid_1's rmse: 1.42852\n",
      "[743]\ttraining's rmse: 1.01945\tvalid_1's rmse: 1.42845\n",
      "[744]\ttraining's rmse: 1.01907\tvalid_1's rmse: 1.42845\n",
      "[745]\ttraining's rmse: 1.01873\tvalid_1's rmse: 1.42848\n",
      "[746]\ttraining's rmse: 1.01835\tvalid_1's rmse: 1.42847\n",
      "[747]\ttraining's rmse: 1.01796\tvalid_1's rmse: 1.42843\n",
      "[748]\ttraining's rmse: 1.0176\tvalid_1's rmse: 1.42845\n",
      "[749]\ttraining's rmse: 1.01718\tvalid_1's rmse: 1.42852\n",
      "[750]\ttraining's rmse: 1.01683\tvalid_1's rmse: 1.42856\n",
      "[751]\ttraining's rmse: 1.01644\tvalid_1's rmse: 1.42857\n",
      "[752]\ttraining's rmse: 1.01603\tvalid_1's rmse: 1.42852\n",
      "[753]\ttraining's rmse: 1.01568\tvalid_1's rmse: 1.42854\n",
      "[754]\ttraining's rmse: 1.01526\tvalid_1's rmse: 1.42853\n",
      "[755]\ttraining's rmse: 1.01488\tvalid_1's rmse: 1.42852\n",
      "[756]\ttraining's rmse: 1.01451\tvalid_1's rmse: 1.42863\n",
      "[757]\ttraining's rmse: 1.01417\tvalid_1's rmse: 1.42869\n",
      "[758]\ttraining's rmse: 1.01379\tvalid_1's rmse: 1.4287\n",
      "[759]\ttraining's rmse: 1.01337\tvalid_1's rmse: 1.4287\n",
      "[760]\ttraining's rmse: 1.01298\tvalid_1's rmse: 1.42877\n",
      "[761]\ttraining's rmse: 1.01263\tvalid_1's rmse: 1.42875\n",
      "[762]\ttraining's rmse: 1.01227\tvalid_1's rmse: 1.4287\n",
      "[763]\ttraining's rmse: 1.01192\tvalid_1's rmse: 1.4287\n",
      "[764]\ttraining's rmse: 1.0116\tvalid_1's rmse: 1.42877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[765]\ttraining's rmse: 1.01125\tvalid_1's rmse: 1.42876\n",
      "[766]\ttraining's rmse: 1.01087\tvalid_1's rmse: 1.42864\n",
      "[767]\ttraining's rmse: 1.01048\tvalid_1's rmse: 1.4286\n",
      "[768]\ttraining's rmse: 1.01009\tvalid_1's rmse: 1.42864\n",
      "[769]\ttraining's rmse: 1.00971\tvalid_1's rmse: 1.4287\n",
      "[770]\ttraining's rmse: 1.00935\tvalid_1's rmse: 1.42876\n",
      "[771]\ttraining's rmse: 1.00899\tvalid_1's rmse: 1.42877\n",
      "[772]\ttraining's rmse: 1.00864\tvalid_1's rmse: 1.42885\n",
      "[773]\ttraining's rmse: 1.00823\tvalid_1's rmse: 1.42894\n",
      "[774]\ttraining's rmse: 1.00785\tvalid_1's rmse: 1.42899\n",
      "[775]\ttraining's rmse: 1.00747\tvalid_1's rmse: 1.42896\n",
      "[776]\ttraining's rmse: 1.00711\tvalid_1's rmse: 1.42896\n",
      "[777]\ttraining's rmse: 1.00676\tvalid_1's rmse: 1.42896\n",
      "[778]\ttraining's rmse: 1.00636\tvalid_1's rmse: 1.42888\n",
      "[779]\ttraining's rmse: 1.00603\tvalid_1's rmse: 1.42891\n",
      "[780]\ttraining's rmse: 1.00566\tvalid_1's rmse: 1.4289\n",
      "[781]\ttraining's rmse: 1.00529\tvalid_1's rmse: 1.42891\n",
      "[782]\ttraining's rmse: 1.00495\tvalid_1's rmse: 1.42893\n",
      "[783]\ttraining's rmse: 1.00458\tvalid_1's rmse: 1.42888\n",
      "[784]\ttraining's rmse: 1.00425\tvalid_1's rmse: 1.42887\n",
      "[785]\ttraining's rmse: 1.00385\tvalid_1's rmse: 1.42896\n",
      "[786]\ttraining's rmse: 1.0035\tvalid_1's rmse: 1.42895\n",
      "[787]\ttraining's rmse: 1.00317\tvalid_1's rmse: 1.42903\n",
      "[788]\ttraining's rmse: 1.00282\tvalid_1's rmse: 1.429\n",
      "[789]\ttraining's rmse: 1.00248\tvalid_1's rmse: 1.42902\n",
      "[790]\ttraining's rmse: 1.00216\tvalid_1's rmse: 1.42911\n",
      "[791]\ttraining's rmse: 1.00178\tvalid_1's rmse: 1.42909\n",
      "[792]\ttraining's rmse: 1.00144\tvalid_1's rmse: 1.42916\n",
      "[793]\ttraining's rmse: 1.0011\tvalid_1's rmse: 1.42916\n",
      "[794]\ttraining's rmse: 1.00073\tvalid_1's rmse: 1.42916\n",
      "[795]\ttraining's rmse: 1.00038\tvalid_1's rmse: 1.42915\n",
      "[796]\ttraining's rmse: 0.99999\tvalid_1's rmse: 1.42912\n",
      "[797]\ttraining's rmse: 0.999673\tvalid_1's rmse: 1.42912\n",
      "[798]\ttraining's rmse: 0.999306\tvalid_1's rmse: 1.42912\n",
      "[799]\ttraining's rmse: 0.99899\tvalid_1's rmse: 1.42918\n",
      "[800]\ttraining's rmse: 0.998628\tvalid_1's rmse: 1.42921\n",
      "[801]\ttraining's rmse: 0.998279\tvalid_1's rmse: 1.42924\n",
      "[802]\ttraining's rmse: 0.997912\tvalid_1's rmse: 1.42934\n",
      "[803]\ttraining's rmse: 0.997598\tvalid_1's rmse: 1.42938\n",
      "[804]\ttraining's rmse: 0.997244\tvalid_1's rmse: 1.42937\n",
      "[805]\ttraining's rmse: 0.996913\tvalid_1's rmse: 1.42941\n",
      "[806]\ttraining's rmse: 0.996538\tvalid_1's rmse: 1.42929\n",
      "[807]\ttraining's rmse: 0.996149\tvalid_1's rmse: 1.42933\n",
      "[808]\ttraining's rmse: 0.995802\tvalid_1's rmse: 1.42938\n",
      "[809]\ttraining's rmse: 0.995472\tvalid_1's rmse: 1.4294\n",
      "[810]\ttraining's rmse: 0.995075\tvalid_1's rmse: 1.42939\n",
      "[811]\ttraining's rmse: 0.994717\tvalid_1's rmse: 1.42947\n",
      "[812]\ttraining's rmse: 0.994356\tvalid_1's rmse: 1.42944\n",
      "[813]\ttraining's rmse: 0.994011\tvalid_1's rmse: 1.42945\n",
      "[814]\ttraining's rmse: 0.99368\tvalid_1's rmse: 1.42952\n",
      "[815]\ttraining's rmse: 0.993296\tvalid_1's rmse: 1.42954\n",
      "[816]\ttraining's rmse: 0.992981\tvalid_1's rmse: 1.42958\n",
      "[817]\ttraining's rmse: 0.992609\tvalid_1's rmse: 1.4296\n",
      "[818]\ttraining's rmse: 0.992284\tvalid_1's rmse: 1.42963\n",
      "[819]\ttraining's rmse: 0.991956\tvalid_1's rmse: 1.4296\n",
      "[820]\ttraining's rmse: 0.991592\tvalid_1's rmse: 1.42959\n",
      "[821]\ttraining's rmse: 0.991249\tvalid_1's rmse: 1.42962\n",
      "[822]\ttraining's rmse: 0.990932\tvalid_1's rmse: 1.42964\n",
      "[823]\ttraining's rmse: 0.990599\tvalid_1's rmse: 1.42966\n",
      "[824]\ttraining's rmse: 0.990279\tvalid_1's rmse: 1.42965\n",
      "[825]\ttraining's rmse: 0.98998\tvalid_1's rmse: 1.42965\n",
      "[826]\ttraining's rmse: 0.989599\tvalid_1's rmse: 1.42959\n",
      "[827]\ttraining's rmse: 0.989295\tvalid_1's rmse: 1.42966\n",
      "[828]\ttraining's rmse: 0.988956\tvalid_1's rmse: 1.4296\n",
      "[829]\ttraining's rmse: 0.988607\tvalid_1's rmse: 1.4296\n",
      "[830]\ttraining's rmse: 0.988252\tvalid_1's rmse: 1.42959\n",
      "[831]\ttraining's rmse: 0.987952\tvalid_1's rmse: 1.42958\n",
      "Early stopping, best iteration is:\n",
      "[731]\ttraining's rmse: 1.02402\tvalid_1's rmse: 1.42828\n"
     ]
    }
   ],
   "source": [
    "y_hat_test_lgb, model, eval_results = run_lgbm(x_dev, y_dev, x_val, y_val, train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_xgb(x_train, y_train, x_val, y_val, x_test):\n",
    "    params = {'objective': 'reg:linear', \n",
    "      'eval_metric': 'rmse',\n",
    "      'eta': 0.001,\n",
    "      'max_depth': 10, \n",
    "      'subsample': 0.6, \n",
    "      'colsample_bytree': 0.6,\n",
    "      'alpha':0.001,\n",
    "      'random_state': 42, \n",
    "      'silent': True}\n",
    "    \n",
    "    xgtrain = xgb.DMatrix(x_train, y_train)\n",
    "    xgvalid = xgb.DMatrix(x_val, y_val)\n",
    "    \n",
    "    eval_results = [(xgtrain, 'train'), (xgvalid, 'valid')]\n",
    "    \n",
    "    model = xgb.train(params, xgtrain, 5000, eval_results, \n",
    "                      maximize=False, \n",
    "                      verbose_eval=100, \n",
    "                      early_stopping_rounds=100)\n",
    "    \n",
    "    xgtest_x = xgb.DMatrix(x_test)\n",
    "    x_hat_test = np.expm1(model.predict(xgtest_x, ntree_limit=model.best_ntree_limit))\n",
    "    return x_hat_test, model, eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:14.1028\tvalid-rmse:14.0157\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:12.7817\tvalid-rmse:12.6954\n",
      "[200]\ttrain-rmse:11.5883\tvalid-rmse:11.5035\n",
      "[300]\ttrain-rmse:10.5103\tvalid-rmse:10.4275\n",
      "[400]\ttrain-rmse:9.53694\tvalid-rmse:9.45707\n",
      "[500]\ttrain-rmse:8.65829\tvalid-rmse:8.58281\n",
      "[600]\ttrain-rmse:7.8655\tvalid-rmse:7.79527\n",
      "[700]\ttrain-rmse:7.14982\tvalid-rmse:7.0865\n",
      "[800]\ttrain-rmse:6.5038\tvalid-rmse:6.44764\n",
      "[900]\ttrain-rmse:5.9212\tvalid-rmse:5.87287\n",
      "[1000]\ttrain-rmse:5.39604\tvalid-rmse:5.35671\n",
      "[1100]\ttrain-rmse:4.92244\tvalid-rmse:4.89257\n",
      "[1200]\ttrain-rmse:4.49581\tvalid-rmse:4.47696\n",
      "[1300]\ttrain-rmse:4.11186\tvalid-rmse:4.10404\n",
      "[1400]\ttrain-rmse:3.76639\tvalid-rmse:3.77037\n",
      "[1500]\ttrain-rmse:3.45583\tvalid-rmse:3.47319\n",
      "[1600]\ttrain-rmse:3.17746\tvalid-rmse:3.20859\n",
      "[1700]\ttrain-rmse:2.92733\tvalid-rmse:2.97308\n",
      "[1800]\ttrain-rmse:2.70339\tvalid-rmse:2.76458\n",
      "[1900]\ttrain-rmse:2.50327\tvalid-rmse:2.58052\n",
      "[2000]\ttrain-rmse:2.32482\tvalid-rmse:2.41886\n",
      "[2100]\ttrain-rmse:2.16606\tvalid-rmse:2.27746\n",
      "[2200]\ttrain-rmse:2.02512\tvalid-rmse:2.15434\n",
      "[2300]\ttrain-rmse:1.9003\tvalid-rmse:2.04744\n",
      "[2400]\ttrain-rmse:1.78977\tvalid-rmse:1.95538\n",
      "[2500]\ttrain-rmse:1.69271\tvalid-rmse:1.87603\n",
      "[2600]\ttrain-rmse:1.60738\tvalid-rmse:1.80865\n",
      "[2700]\ttrain-rmse:1.53191\tvalid-rmse:1.7508\n",
      "[2800]\ttrain-rmse:1.46582\tvalid-rmse:1.70173\n",
      "[2900]\ttrain-rmse:1.40777\tvalid-rmse:1.66003\n",
      "[3000]\ttrain-rmse:1.3573\tvalid-rmse:1.62511\n",
      "[3100]\ttrain-rmse:1.31272\tvalid-rmse:1.5955\n",
      "[3200]\ttrain-rmse:1.2739\tvalid-rmse:1.57067\n",
      "[3300]\ttrain-rmse:1.2396\tvalid-rmse:1.54972\n",
      "[3400]\ttrain-rmse:1.20962\tvalid-rmse:1.53238\n",
      "[3500]\ttrain-rmse:1.18308\tvalid-rmse:1.51769\n",
      "[3600]\ttrain-rmse:1.16024\tvalid-rmse:1.50552\n",
      "[3700]\ttrain-rmse:1.13983\tvalid-rmse:1.49514\n",
      "[3800]\ttrain-rmse:1.12186\tvalid-rmse:1.48673\n",
      "[3900]\ttrain-rmse:1.10574\tvalid-rmse:1.47968\n",
      "[4000]\ttrain-rmse:1.09136\tvalid-rmse:1.47347\n",
      "[4100]\ttrain-rmse:1.07835\tvalid-rmse:1.46839\n",
      "[4200]\ttrain-rmse:1.0666\tvalid-rmse:1.46417\n",
      "[4300]\ttrain-rmse:1.05566\tvalid-rmse:1.46067\n",
      "[4400]\ttrain-rmse:1.04634\tvalid-rmse:1.45772\n",
      "[4500]\ttrain-rmse:1.03756\tvalid-rmse:1.45532\n",
      "[4600]\ttrain-rmse:1.02912\tvalid-rmse:1.45305\n",
      "[4700]\ttrain-rmse:1.02116\tvalid-rmse:1.45141\n",
      "[4800]\ttrain-rmse:1.01417\tvalid-rmse:1.45005\n",
      "[4900]\ttrain-rmse:1.0077\tvalid-rmse:1.44871\n",
      "[4999]\ttrain-rmse:1.00114\tvalid-rmse:1.44746\n"
     ]
    }
   ],
   "source": [
    "y_hat_test_xgb, model, eval_results = run_xgb(x_dev, y_dev, x_val, y_val, train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'../input/sample_submission.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-190-a7022d6eba41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msubmission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/sample_submission.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msubmission_lgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msubmission_lgb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"target\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_hat_test_lgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'../input/sample_submission.csv' does not exist"
     ]
    }
   ],
   "source": [
    "submission = pd.read_csv('../input/sample_submission.csv')\n",
    "\n",
    "submission_lgb = pd.DataFrame()\n",
    "submission_lgb[\"target\"] = y_hat_test_lgb\n",
    "\n",
    "submission_xgb = pd.DataFrame()\n",
    "submission_xgb[\"target\"] = y_hat_test_xgb\n",
    "\n",
    "submission[\"target\"] = (sub_lgb[\"target\"] * 0.5 + sub_xgb[\"target\"] * 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
